# -*- coding: utf-8 -*-
"""Untitled100.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/108TekjX5Tz2lcqtZMIA-5d7Llqf6K2Cx
"""

import os
import torch
import torchaudio
import librosa
import pandas as pd
import numpy as np
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader
from transformers import Wav2Vec2Model, Wav2Vec2Processor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import torch.nn as nn

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ------------------------
# 1. Dataset
# ------------------------
class GrammarAudioDataset(Dataset):
    def __init__(self, df, audio_dir, processor, is_test=False):
        self.df = df
        self.audio_dir = audio_dir
        self.processor = processor
        self.is_test = is_test

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        audio_file = os.path.join(self.audio_dir, self.df.iloc[idx]['filename'])
        waveform, sr = torchaudio.load(audio_file)
        waveform = librosa.resample(waveform.squeeze().numpy(), orig_sr=sr, target_sr=16000)

        inputs = self.processor(waveform, sampling_rate=16000, return_tensors="pt", padding=True)
        input_values = inputs.input_values.squeeze(0)

        if self.is_test:
            return input_values, self.df.iloc[idx]['filename']
        else:
            label = torch.tensor(self.df.iloc[idx]['label'], dtype=torch.float32)
            return input_values, label

# ------------------------
# 2. Collate Function
# ------------------------
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base")

def custom_collate_fn(batch):
    if isinstance(batch[0][-1], str):  # test mode
        input_values = [item[0] for item in batch]
        file_names = [item[1] for item in batch]
        inputs = processor.pad({"input_values": input_values}, padding=True, return_tensors="pt")
        return inputs.input_values, file_names
    else:  # train/val
        input_values = [item[0] for item in batch]
        labels = [item[1] for item in batch]
        inputs = processor.pad({"input_values": input_values}, padding=True, return_tensors="pt")
        labels = torch.stack(labels)
        return inputs.input_values, labels

# ------------------------
# 3. Model
# ------------------------
class GrammarScoringModel(nn.Module):
    def __init__(self):
        super(GrammarScoringModel, self).__init__()
        self.wav2vec = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base")
        self.fc = nn.Sequential(
            nn.Linear(768, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 1)
        )
        self.sigmoid = nn.Sigmoid()
        self.label_min = 0.0
        self.label_max = 5.0

    def forward(self, input_values):
        outputs = self.wav2vec(input_values=input_values)
        pooled = outputs.last_hidden_state.mean(dim=1)
        score = self.fc(pooled)
        score = self.sigmoid(score)  # scale to 0-1
        scaled_score = score * (self.label_max - self.label_min) + self.label_min  # scale to 0-5
        return scaled_score.squeeze(1)

# ------------------------
# 4. Training Function
# ------------------------
def train_fn(model, dataloader, optimizer, criterion):
    model.train()
    for input_values, labels in dataloader:
        input_values = input_values.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(input_values)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        return loss.item()

# ------------------------
# 5. Evaluation
# ------------------------
def evaluate_fn(model, dataloader):
    model.eval()
    all_labels = []
    all_outputs = []
    with torch.no_grad():
        for input_values, labels in dataloader:
            input_values = input_values.to(device)
            labels = labels.to(device)

            outputs = model(input_values)
            all_labels.append(labels.cpu().numpy())
            all_outputs.append(outputs.cpu().numpy())

    all_labels = np.concatenate(all_labels, axis=0)
    all_outputs = np.concatenate(all_outputs, axis=0)

    mse = mean_squared_error(all_labels, all_outputs)
    r2 = r2_score(all_labels, all_outputs)
    return mse, r2, all_outputs, all_labels

# ------------------------
# 6. Main Training Script
# ------------------------
def main():
    train_df = pd.read_csv('train.csv')
    test_df = pd.read_csv('test.csv')

    train_split, val_split = train_test_split(train_df, test_size=0.2, random_state=42)

    train_split = train_split.head(2)
    val_split = val_split.head(2)

    train_audio_dir = "/content/drive/MyDrive/audios/train"
    test_audio_dir = "/content/drive/MyDrive/audios/test"

    train_dataset = GrammarAudioDataset(train_split, train_audio_dir, processor)
    val_dataset = GrammarAudioDataset(val_split, train_audio_dir, processor)

    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=custom_collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=custom_collate_fn)

    model = GrammarScoringModel().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)
    criterion = nn.MSELoss()

    best_mse = float('inf')

    for epoch in range(10):
        print(f"\nEpoch {epoch + 1}")
        train_loss = train_fn(model, train_loader, optimizer, criterion)
        print(f"Train Loss: {train_loss:.4f}")

        val_mse, _, _, _ = evaluate_fn(model, val_loader)
        if val_mse < best_mse:
            torch.save(model.state_dict(), 'best_model.pt')
            best_mse = val_mse

    # ------------------------
    # Final Evaluation after Training
    # ------------------------
    print("\nEvaluating Best Model on Validation Set...")
    model.load_state_dict(torch.load("best_model.pt"))
    val_mse, val_r2, _, _ = evaluate_fn(model, val_loader)
    print(f"Final Val MSE: {val_mse:.4f} | Final Val RÂ²: {val_r2:.4f}")

# ------------------------
# 7. Inference
# ------------------------
def inference():
    test_df = pd.read_csv('test.csv').head(2)

    test_audio_dir = "/content/drive/MyDrive/audios/test"
    model = GrammarScoringModel().to(device)
    model.load_state_dict(torch.load("best_model.pt"))

    test_dataset = GrammarAudioDataset(test_df, test_audio_dir, processor, is_test=True)
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=custom_collate_fn)

    model.eval()
    predictions = []
    file_names = []

    with torch.no_grad():
        for input_values, file_name in tqdm(test_loader, desc="Inference"):
            input_values = input_values.to(device)
            output = model(input_values)
            predictions.append(output.item())
            file_names.append(file_name[0])

    submission = pd.DataFrame({
        "file_name": file_names,
        "score": [np.clip(round(p, 2), 0, 5) for p in predictions]
    })
    submission.to_csv("submission.csv", index=False)
    print("Submission saved to submission.csv")

if __name__ == "__main__":
    main()
    inference()